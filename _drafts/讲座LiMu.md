

Good Enough？

语言模型已经足够大了

- 约50Ttoken的预训练文本
- 约500B 参数（不含MOE）
- 至多5T参数的闭源模型（MOE）

  

非SST与TTS 的语音E2E模型产生，并且足够好用

  

已经很好的普通的音乐生成器

  

足够好，已经有灵魂的照片生成器

  

符合现实物理的视频生成器（三种工具，或许已经可以初步满足使用的需求）

  

多模态与具身智能与新的交互方式还有很多发展的空间

  

Application

当一领域能够被采集足够多的数据，而这个领域本身足够稳定，才有使用模型自动化的潜力。当问题变得复杂，那么现有的语言模型技术可能就无法处理这种问题，需要进一步的技术迭代。

  

关于Model

Pre train 和 post train 同等重要，或许post train比前面的预训练对于普通研究者而言更为重要。

通用模型是垂直模型的基础，但垂直模型在同等基础下处理特殊问题的效果明显会更好

无论通用还是垂直，高质量的Data都非常重要

LLM还是ML，但是变得非常大，因为变大了，所以很难。