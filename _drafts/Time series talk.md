## Time series talk
基础预测模型的基本限制——多模态与更加严谨的评估的重要性

时间序列的预测是一个非常基础的话题，如果我们给出一个随机游走的序列（他没有任何内在的模式可以被发现），那对这个序列最好的预测是naive的，也就是用前一刻观测值作为下一刻预测值，他的性能往往大于我们使用BP，SVM，RF等模型建模。

股票市场与随机游走很像，他不是过去价格的函数，而是未来预期的体现。股价本身具有很低的信噪比，金融领域的有效市场假说认为股价具有鞅性。因此，超出naive预测的股价预测是不可能的，金融领域实际上也不在研究这个，他们更关注风险与波动而不是回报。如果我们认为市场本身是低效的，那我们也只能取得比naive预测好一点点的方法；除了股票以外的很多金融产品都满足这个叙述。

事实上，很多在顶尖会议上发表的相关文章都声称自己在很多金融预测领域实现了SOTA，而他们都不如最naive的预测，虽然计算时间不断膨胀，但性能没有。而他们经常只声称自己实现了在DL方法中的SOTA，不考虑naive方法。

在金融数据以外，DL研究者也在天气与电力数据上经常展开预测，而展开长期预测（大于两周），气象学家认为这无异于随机猜测（长期预测不存在）。打开他们的文章，他们确实比较了那些更为naive的方法，比如ARIMA与ETS，但是模型的基本设置往往不符合需求，或者他们选取的基准模型不适用于对应的序列，当我们考虑使用DHR-ARIME这种复杂度较高的合适的模型，基准模型的效果反而会更好。

为了让自己的模型效果更好，部分学者往往会调整模型的超参数或者修改测试集的大小（最后一个不满足一个batch的测试集被丢弃）。在很多文章中，同一个方法在不同文章中的性能甚至会发生很大的变化，他们使用各种不同的测试标准来实现SOTA，但很多远不如几十年前的baseline

全局模型与局部模型（使用单一时间序列构建的模型或多个时间序列构建的预测模型）

事实上，只有深度学习技术能够利用大量的多来源的时间序列构建全局模型；有研究表明在毫不相关的数据上训练全局模型再进行领域的微调，就可以实现本地模型的效果。这种思想再基础的统计领域也出现过，称为James-Stein悖论。它允许我们利用完全无关的数据改进预测的效果。这也是正则化理论的基础，我们忽视对系数的估计换到更好的预测效果。

但是，全局上有效的全局模型不能保证我们的特定局部数据上有效，简单的全局模型不能作为通向TS基础模型的正确导论。全局模型（一般指LLM 4 TS）再学习的过程中会将各种来源的数据混为一谈，导致没法结合真实的情景和对应的训练数据做出精准的预测，事实上算法会将不同的隐含模式平均，而不是分别加以利用。语言模型也存在这种隐含模式错误的问题，但是我们可以在一轮轮对话中纠正模型，这种错误很容易消除。但TS不然。

想要在LLM4TS解决这个问题一定需要利用上下文 context 这将是TS基准模型的基本路线，单纯的时间序列缺少足够的可以被利用的信息。