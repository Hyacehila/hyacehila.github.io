---
layout: blog-post
title: "回顾2025和过去的20年"
date: 2026-01-02 22:00:00 +0800
categories: [随笔]
tags: [Self]
author: Hyacehila
excerpt: 总结2025，以及过去的24年，我做了什么，又应该去做些什么
---

# 写作进度

- 开始时间：2026-01-02
- 状态：草稿（不会在生产构建中展示）

## 目标

- 用 TRL 的 `GRPOTrainer` 跑通一个最小可行训练流程
- 设计一个“可验证奖励”（例如：格式校验/单测通过/数学答案正确）
- 记录关键坑点与调参经验

## 大纲（待完善）

1. 数据与提示词格式
2. 奖励函数（Reward Function）设计
3. 训练参数与稳定性
4. 评估：离线指标 vs 在线可验证信号
5. 常见问题（OOM、发散、奖励欺骗等）

## TODO

- [ ] 补齐示例代码与运行命令
- [ ] 给出一套可复现的最小数据集
- [ ] 对比 DPO / PPO 的差异与选择建议

